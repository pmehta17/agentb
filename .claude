# Project Guide: Reflexive UI Automation Agent (Agent B)

This document outlines the architecture, module responsibilities, and development rules for our AI agent. Please use this as your single source of truth when generating or modifying code.

## 1.0 Project Goal

Our goal is to build a "reflexive" AI agent (Agent B) that can receive open-ended, natural language tasks (e.g., "Create a project in Linear") and execute them by navigating a live web app.

**Core Principles:**

1.  **Generalizable:** Must work on unseen tasks and apps.
2.  **Robust:** Must handle dynamic UI (modals, menus) without hardcoded selectors.
3.  **Reflexive:** Must be able to fail, understand the failure, and re-plan to recover.
4.  **Efficient:** Must learn from successful tasks to reduce future latency and cost.

---

## 2.0 System Architecture

The system is a closed-loop architecture with six primary modules.

1.  **Orchestrator:** The central "nervous system." Manages the main loop.
2.  **Skills Library:** The "long-term memory." A vector cache of successful plans.
3.  **Planner (LLM):** The "high-level brain." Generates and refines text-based plans.
4.  **Executor (Browser):** The "hands." Performs browser actions and simple DOM checks.
5.  **Perceptor (VLM):** The "eyes." A powerful vision model for complex visual search.
6.  **State Capturer (Observer):** The "photographer." Detects and saves screenshots of UI changes.

---

## 3.0 Module Responsibilities & Rules

### 3.1 Orchestrator (`orchestrator.py`)

- **Tech:** Python 3.10+ (`asyncio`)
- **Responsibilities:**
  - Manages the main `async` execution loop.
  - **"Cache First" Rule:** On receiving a task, it _must_ query the `SkillsLibrary` first.
  - **"Plan Fallback" Rule:** Only calls the `Planner` if the `SkillsLibrary` returns no match.
  - **"DOM-First" Perception Rule:** For _every_ step, it _must_ try the `Executor.find_element_by_text()` first.
  - **"Vision Fallback" Rule:** Only calls the `Perceptor.find_element()` if the DOM-first pass returns `None`.
  - **Re-planning:** Must wrap all execution steps in a `try...except` block. On failure, it bundles context (goal, error, screenshot) and calls `Planner.regenerate_plan()`.
  - **Success Validation:** Must call `Planner.validate_success()` after the final step.
  - **Skill Saving:** If a _new_ task succeeds, it _must_ call `SkillsLibrary.add_skill()` to save the plan.

### 3.2 Skills Library (`skills.py`)

- **Tech:** `chromadb` (or FAISS) + `sentence-transformers`
- **Responsibilities:**
  - `add_skill(task: str, plan: dict)`: Generates an embedding for the task and saves the `plan` JSON.
  - `find_skill(task_embedding: list) -> Optional[dict]`: Performs a semantic search. Returns the plan JSON _only if_ the similarity score is above a high confidence threshold (e.g., `0.95`).

### 3.3 Planner (LLM Agent) (`planner.py`)

- **Tech:** `openai` or `anthropic` (Text-only models, e.g., GPT-4o, Claude 3 Sonnet)
- **Responsibilities:**
  - `generate_initial_plan()`: Generates a new plan adhering to the `Rich Action Schema`.
  - `regenerate_plan()`: Generates a _corrected_ plan based on failure context.
  - `validate_success()`: The final "success detector." Takes the goal and final screenshot, returns `True` or `False`.
- **CRITICAL RULE: Rich Action Schema**

  - All plans generated by this module _must_ follow this JSON structure:

  ```json
  [
    {
      "step": 1,
      "action": "CLICK",
      "target_description": "the 'New Project' button in the left sidebar",
      "value": null,
      "semantic_role": "primary_action",
      "required_state": "projects_list_visible"
    },
    {
      "step": 2,
      "action": "TYPE",
      "target_description": "the 'Project name' input field",
      "value": "My New AI Project",
      "semantic_role": "form_field",
      "required_state": "create_project_modal_open"
    }
  ]
  ```

### 3.4 Executor (Browser Agent) (`executor.py`)

- **Tech:** `playwright`
- **Responsibilities:**
  - Must be a "dumb" module. **No AI logic.**
  - Expose low-level actions: `click(x, y)`, `type(x, y, text)`, `Maps(url)`, `get_screenshot()`.
  - **`find_element_by_text(text: str) -> Optional[dict]`:**
    - This is the "cheap first pass."
    - Uses `page.get_by_text()`.
    - **CRITICAL:** Must return `{"x": y}` coordinates _if and only if_ it finds _exactly one_ visible element.
    - If it finds 0 or >1 elements, it _must_ return `None`.

### 3.5 Perceptor (Multimodal Agent) (`perceptor.py`)

- **Tech:** `openai` or `anthropic` (Multimodal models, e.g., GPT-4o, Claude 3 Vision)
- **Responsibilities:**
  - This is the "expensive" vision fallback.
  - `find_element(screenshot: bytes, step: dict) -> dict`:
    - Receives the screenshot and the _full step object_ from the plan for context.
    - Returns `{"x": y}` coordinates.
    - If it fails, it _must_ return a descriptive `Failure` object/exception (e.g., "Cannot find 'Archive' button, but I see a 'Delete' button.") to aid re-planning.

### 3.6 State Capturer (`capturer.py`)

- **Tech:** `Pillow (PIL)` + `pixelmatch`
- **Responsibilities:**
  - `capture_state(step_name: str)`: Saves the current screenshot to the dataset.
  - **`wait_for_change()`:**
    - This is the core non-URL state solution.
    - Called _after_ an action (like `click`).
    - **Logic:**
      1.  Take `before.png`.
      2.  Wait for `networkidle`.
      3.  Start polling: Take `after.png`, compare with `before.png` using `pixelmatch`.
      4.  Exit _only_ when `diff_percentage > THRESHOLD` (e.g., 2%).

---

## 4.0 Key Workflows

### 4.1 Cache Hit (Efficient Path)

1.  **Task:** "Make a new Notion page."
2.  **Orchestrator** -> `SkillsLibrary`: Finds a match.
3.  **Orchestrator** -> `Executor`: Executes the cached plan (DOM-first).
4.  **Orchestrator** -> `Planner`: `validate_success()` -> `True`.
5.  **Result:** Task complete. **Zero Planner calls.**

### 4.2 Cache Miss & Re-planning (Robust Path)

1.  **Task:** "Archive my 'Q4-bugs' project."
2.  **Orchestrator** -> `SkillsLibrary`: `None`.
3.  **Orchestrator** -> `Planner`: `generate_initial_plan()`.
4.  **Orchestrator** executes Step 1 (OK).
5.  **Orchestrator** executes Step 2 ("Click 'Archive'"):
    - `Executor.find_element_by_text("Archive")` -> `None`.
    - `Perceptor.find_element(...)` -> **Failure** ("Button not found, see '...' menu").
6.  **Orchestrator** `catch` failure -> `Planner.regenerate_plan(...)`.
7.  **Planner** returns new plan: ["Click '...' menu", "Click 'Archive'"].
8.  **Orchestrator** executes new plan (OK).
9.  **Orchestrator** -> `Planner.validate_success()` -> `True`.
10. **Orchestrator** -> `SkillsLibrary.add_skill()` (saves the _successful_ 3-step plan).
11. **Result:** Task complete. Agent recovered and learned a new skill.

## Suggested File structure:

You may modify if optimal.

```
/reflexive-agent-project
├── /agent
│   ├── __init__.py
│   ├── orchestrator.py    # Module 1: Main loop, re-planning logic
│   ├── skills.py          # Module 2: SkillsLibrary class (ChromaDB logic)
│   ├── planner.py         # Module 3: Planner class (LLM API calls)
│   ├── executor.py        # Module 4: Executor class (Playwright wrapper)
│   ├── perceptor.py       # Module 5: Perceptor class (VLM API calls)
│   ├── capturer.py        # Module 6: StateCapturer class (Pixelmatch logic)
│   └── utils.py           # Helper functions, custom exceptions
│
├── /dataset                 # Deliverable: Output directory for screenshots
│   └── .gitkeep
│
├── /db                      # Local vector database storage (for ChromaDB)
│   └── .gitkeep
│
├── .env
├── config.py                # API keys, thresholds, dataset paths
├── main.py                  # Main entry point to run the agent
├── requirements.txt         # All Python dependencies
├── README.md                # Project overview and setup instructions
└── CLAUDE.md                # Development guide for AI

```
